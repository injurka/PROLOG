<!-- TABLE OF CONTENTS -->
<div id="readme-top" />
<h1>Содержание</h1>
<ol>
  <li><a href="#1">Представление правил в продукционном программировании</a></li>
  <li><a href="#2">Семантические и ассоциативные сети</a></li>
  <li><a href="#3">Фреймовая модель представления знаний</a></li>
  <li><a href="#4">Обучение сети по методу обратного распространения ошибки</a></li>
  <li><a href="#5">Понятие, и особенности интеллектуальных информационных систем</a></li>
  <li><a href="#6">Системы, основанные на знаниях</a></li>
  <li><a href="#7">Модели представления знаний</a></li>
  <li><a href="#8">Продукционная модель (правила продукций)</a></li>
  <li><a href="#9">Представление и обработка непределенности в продукционных системах</a></li>
  <li><a href="#10">Байесова модель</a></li>
  <li><a href="#11">Сетевые модели и графы</a></li>
  <li><a href="#12">Рейтинговая модель</a></li>
  <li><a href="#13">Нечеткая модель</a></li>
  <li><a href="#14">Фреймы и объективно-ориентирована представление знаний</a></li>
  <li><a href="#15"> Ситуационный подход в представлении знаний и выводе решений</a></li>
  <li><a href="#16">Системы интеллектуального анализа данных. Извлечение знаний из данных</a></li>
  <li><a href="#17">Архитектура многослойных нейронных сетей</a></li>
  <li><a href="#18">Активация нейронной сети посредством прямого распространения</a></li>
  <li><a href="#19">Распараллеливание процесса обучения нейронных сетей с помощью TensorFlow</a></li>
  <li><a href="#20">Классификация изображений с помощью глубоких сверточных нейронных сетей</a> <b>NOPE</b></li>
  <li><a href="#21">Строительные блоки сверточных нейронных сетей</a> <b>NOPE</b></li>
  <li><a href="#22">Понятие сверточных нейронных сетей</a></li>
  <li><a href="#23">Выполнение дискретных сверток в сверточной нейронной сети</a> <b>NOPE</b></li>
  <li><a href="#24">Работа с множественными входными или цветовыми каналами в сверточной нейронной сети</a> <b>NOPE</b></li>
  <li><a href="#25">Архитектура многослойной сверточной нейронной сети</a> <b>NOPE</b></li>
</ol>
<hr/>
<br />

##

<h2 id="1"> 1. Представление правил в продукционном программировании </h2>

Продукционная МПЗ (МПЗ - модель представления знаний(или правил))

В основе продукционной модели представления знаний находится конструктивная часть, продукция(правило:

<hr/>
IF <условие>, THEN <действие>
<hr/>

Продукция состоит из двух частей: условие — антецендент, действие — консеквент. Условия можно сочетать с помощью логических функций AND, OR.
Антецеденты и консеквенты составленных правил формируются из атрибутов и значений.
Пример: <br/>

<hr/>
IF температура реактора подымается THEN добавить стержни в реактор
<hr/>

В базе данных продукционной системы хранятся правила, истинность которых установлена к за ранее при решении определенной задачи.  
Правило срабатывает, если при сопоставлении фактов, содержащихся в базе данных с антецедентом правила, которое подвергается проверке, имеет место совпадение. Результат работы правила заносится в базу данных.

<p align="right"><a href="#readme-top">К содержанию ^</a></p>

##

<h2 id="2"> 2. Семантические и ассоциативные сети</h2>

<h4>Семанти́ческая сеть</h4>

<b>Семанти́ческая сеть</b> — информационная модель предметной области, имеет вид ориентированного графа.
Вершины графа соответствуют объектам предметной области, а дуги (рёбра) задают отношения между ними.
Объектами могут быть: <u>понятия, события, свойства, процессы</u>. Таким образом, <b>семантическая сеть</b> — это один из способов представления знаний.

В названии соединены термины из двух наук:

1. <b>Семантика</b> в языкознании изучает смысл единиц языка, а сеть в математике представляет собой разновидность графа — набора вершин, соединённых дугами (рёбрами), которым присвоено некоторое число. В семантической сети роль вершин выполняют понятия базы знаний
2. <b>Дуги</b> (причем направленные) задают отношения между ними. Таким образом, семантическая сеть отражает семантику предметной области в виде понятий и отношений.

Неправильно приравнивать друг другу понятия «Семантическая сеть» и «Семантическая паутина». Хотя эти понятия не эквивалентны, тем не менее, они связаны.

- <h5>Структура</h5>
    Математика позволяет описать большинство явлений в окружающем мире в виде логических высказываний. Семантические сети возникли как попытка визуализации математических формул. Основным представлением для семантической сети является граф.
    Однако не стоит забывать, что за графическим изображением непременно стоит строгая математическая запись и что обе эти формы отображают одно и то же.

- <h5>Графическое представление</h5>
    Основной формой представления семантической сети является граф.
    Понятия семантической сети записываются в овалах или прямоугольниках и соединяются стрелками с подписями — дугами.
    Это наиболее удобно воспринимаемая человеком форма. Её недостатки проявляются,
    когда мы начинаем строить более сложные сети или пытаемся учесть особенности естественного языка. Схемы семантических сетей,
    на которых указаны направления навигационных отношений, называют картами знаний, а их совокупность,
    позволяющая охватить большие участки семантической сети, атласом знания.

- <h5>Математическая запись</h5>
    В математике граф представляется множеством вершин V и множеством отношений между ними E.
    Используя аппарат математической логики, приходим к выводу,
    что каждая вершина соответствует элементу предметного множества, а дуга — предикату.

- <h5>Лингвистическая запись</h5>
    В лингвистике отношения фиксируются в словарях и в тезаурусах. В словарях в определениях через род и видовое отличие родовое понятие занимает определённое место.
    В тезаурусах в статье каждого термина могут быть указаны все возможные его связи с другими родственными по теме терминами.
    От таких тезаурусов необходимо отличать тезаурусы информационно-поисковые с перечнями ключевых слов в статьях, которые предназначены для работы дескрипторных поисковых систем.

<h4>Ассоциативная сеть</h4>
<b>Ассоциативная сеть</b> - основное отличие ассоциативной сети от семантической в том, что мы указываем не смысл (сущность) связи между объектами, а просто говорим об их ассоциировании,
о силе, уровне ассоциаций. Под ассоциацией понимается семантическая репрезентативность в смысле.
При этом надо различать индивидуальные, настраиваемые модели ассоциаций (и их объединение в групповые) и усредненные (статистические),
такие как, например, статистики запросов в поисковых машинах. Кроме этого, следует различать модели ассоциаций непосредственно субъекта и модель передачи знаний между субъектами.

<p align="right"><a href="#readme-top">К содержанию ^</a></p>

##

<h2 id="3"> 3. Фреймовая модель представления знаний</h2>

<b>Фреймовая модель представления знаний</b> – была предложена М.Минским в 1979 г. как структура знаний для восприятия пространственных сцен.
Фреймом называется также и формализованная модель для отобра­же­ния образа.

В качестве идентификатора фрейму присваивается имя фрей­ма. Это имя должно быть единственным во всей фреймовой системе.

Фрейм имеет определенную внутреннюю структуру, состоящую из мно­­жества элементов, называемых слотами, которым также присва­и­ва­ют­ся имена.
За слотами следуют шпации, в которые помещают данные, представляющие текущие значения слотов.
Каждый слот в свою очередь представляется опре­де­ленной струк­турой данных.
В значение слота подставляется конкретная инфор­ма­ция, относящаяся к объекту, описываемому этим фреймом.

Модель фрейма является достаточно универсальной, поскольку позволяет отобразить все многообразие знаний о мире:

- через фреймы-структуры, для обозначения объектов и понятий (заем, залог, вексель);
- через фреймы-роли (менеджер, кассир, клиент);
- через фреймы-сценарии (банкротство, собрание акционеров, празднование именин);
- через фреймы-ситуации (тревога, авария, рабочий режим устройства) и др.

<u>Основным преимуществом фреймов</u> как модели пред­став­ления знаний является то, что она отражает концептуальную основу ор­ганизации па­мяти чело­века, а также ее гибкость и наглядность. Наиболее ярко дос­то­ин­ства фреймовых систем представления знаний проявляются в том слу­чае, если родовидовые связи изменяются нечасто и предметная область насчитывает немного исключений. Во фреймовых системах данные о ро­до­­видовых связях хранятся явно, как и знания других типов. Значения сло­тов представляются в системе в единственном экземпляре, поскольку вклю­чаются только в один фрейм, описывающий наиболее понятия из всех тех, которые содержит слот с данным именем. Такое свойство систем фрей­мов обеспечивает экономное размещение базы знаний в памяти ком­пью­тера. Еще одно достоинство фреймов состоит в том, что значение лю­бо­го слота может быть вычислено с помощью соответствующих процедур или найдено эвристическими методами. То есть фреймы позволяют ма­ни­пу­лировать как декларативными, так и процедурными знаниями.

<u>К недостаткам фреймовых систем</u> относят их относительно высокую сложность, что проявляется в снижении скорости работы механизма вы­во­да и увеличения трудоемкости внесения изменений в родовую иерар­хию. Поэтому при разработке фреймовых систем уделяют наглядным способам отображения и эффективным средствам редактирования фреймовых структур.

<p align="right"><a href="#readme-top">К содержанию ^</a></p>

##

<h2 id="4"> 4. Обучение сети по методу обратного распространения ошибки</h2>

<b>Алгоритм обратного распространения ошибки</b> — популярный алгоритм обучения нейронных сетей прямого распространения (многослойных персептронов). Относится к методам обучения с учителем, поэтому требует, чтобы в обучающих примерах были заданы целевые значения. Также является одним из наиболее известных алгоритмов машинного обучения

<b>Персептрон</b> - математическая или компьютерная модель восприятия информации мозгом

Основная идея этого метода состоит в распространении сигналов ошибки от выходов сети к её входам, в направлении обратном прямому распространению сигналов в обычном режиме работы. Барцев и Охонин предложили обобщающий метод («принцип двойственности»), применимый к более широкому классу систем, включая системы с запаздыванием, распределённые системы.

<div class="back-propagation">
<img src="./assets/back-propagation.png">
Вот кароче формула делайте с ней че хотите
</div>  
<br/>

для вычисления величин коррекции весов нейронов в ее скрытых слоях, где
k — число выходных нейронов сети,
y — целевое значение,
y′— фактическое выходное значение. Алгоритм является итеративным и использует принцип обучения «по шагам» (обучение в режиме on-line), когда веса нейронов сети корректируются после подачи на ее вход одного обучающего примера.

На каждой итерации происходит два прохода сети — прямой и обратный. На прямом входной вектор распространяется от входов сети к ее выходам и формирует некоторый выходной вектор, соответствующий текущему (фактическому) состоянию весов. Затем вычисляется ошибка нейронной сети как разность между фактическим и целевым значениями. На обратном проходе эта ошибка распространяется от выхода сети к ее входам, и производится коррекция весов нейронов в соответствии с правилом:

<hr/>
Таким образом, алгоритм использует так называемый стохастический градиентный спуск, «продвигаясь» в многомерном пространстве весов в направлении антиградиента с целью достичь минимума функции ошибки.

На практике обучение продолжают не до точной настройки сети на минимум функции ошибки, а до тех пор, пока не будет достигнуто достаточно точное его приближение. Это позволит, с одной стороны, уменьшить число итераций обучения, а с другой — избежать переобучения сети.

<hr/>
<p align="right"><a href="#readme-top">К содержанию ^</a></p>

##

<h2 id="5"> 5. Понятие и особенности интеллектуальных информационных систем</h2>

<b>Интеллектуальная информационная система</b> (ИИС) - комплекс программных, лингвистических и логико-математических средств для реализации основной задачи – осуществления поддержки деятельности человека и поиска информации в режиме продвинутого диалога на естественном языке. ИИС являются разновидностью интеллектуальной системы, а также одним из видов информационных систем.

Для интеллектуальных информационных систем характерны
следующие особенности:

- развитые коммуникативные способности;
- умение решать сложные плохо формализуемые задачи;
- способность к самообучению;
- адаптивность.

Коммуникативные способности ИС характеризуют способ
взаимодействия (интерфейса) конечного пользователя с системой, в
частности возможность формулирования произвольного запроса в
диалоге с ИС на языке, максимально приближенном к естественному.

<p align="right"><a href="#readme-top">К содержанию ^</a></p>

##

<h2 id="6"> 6. Системы основанные на знаниях </h2>

В литературе существуют разные определения термина <b>знание</b>. Следует иметь ввиду, что речь идет не о знаниях вообще, а о том, что понимается под этим термином именно в компьютерных системах, в ИИС.

Так, для знаний дается следующее определение:

<b>Знания</b> – это закономерности предметной области (принципы, связи, законы), полученные в результате практической деятельности и профессионального опыта, позволяющие специалистам ставить и решать задачи в этой области.

Часто определяют понятие <u>знания</u> отличиями от понятия <u>данные</u>.

<b>Данные</b> – это отдельные факты, характеризующие объекты, процессы и явления предметной области, а также их свойства.

Сравнение функций данных и знаний позволяет дать следующее, достаточно общее определение.

<b>Знания</b> (в компьютерной системе) – закодированные некоторым образом сведения об объектах предметной области, их взаимосвязях и особенностях поведения, а также о способах решения задач. Эти сведения в условиях, характеризуемых некоторыми данными, служат инструментом решения задач.

То есть можно сказать, что <u>знания</u> – это инструмент решения задач, а <u>данные</u> - информационное обеспечение такого решения.

<b>Знания</b> – это высокоструктурированные сведения, самодостаточные, не требующие дополнительных программ для интерпретации. Знания обладают семантикой (смыслом) и прагматикой (руководством к действию) в контексте определенной задачи. Данные – это конкретные значения атрибутов объектов, процессов или отношений (констант и переменных, числовых и символьных).

Так, в компьютере могут присутствовать знания о временах года, о том, когда в данном городе летом начинает темнеть, о том, какие районы города и в какое время считаются небезопасными и т.п. Конкретная ситуация может характеризоваться такими данными, как время года, время суток, место нахождения человека. «Наложение» этих данных на знания может привести к суждению о том, что в данном месте в данное время находиться этому человеку опасно (и насколько, опасно). В более сложном случае вывод об опасности нахождения человека в сложившейся ситуации может продолжиться поиском и предложением вариантов действий для этого человека, в том числе, с учетом его цели и его предпочтений.

Классификация знаний выполняется по разным признакам. По характеру и трудности выявления и последующей формализации знаний в компьютере их разделяют на два типа:

- знания 1-го рода (называют еще артикулируемые). Это знания, которые хорошо представляются в виде текстов. Они, соответственно, воплощены в разных учебниках, документах, технологических картах, рекомендациях и т.п.;

- знания 2-го рода (неартикулируемые). Эти знания отражают индивидуальный опыт решения профессиональных задач, они трудно формализуются и, как правило, непредставимы или труднопредставимы с помощью обычных текстов. Эти знания представляются в ИИС с помощью специальных моделей представления знаний, позволяющих не только закодировать их в памяти компьютера. Но и использовать для имитации рассуждения и автоматизированном выводе решений.

По степени объективности знаний они разделяются на глубинные (общепризнанные, отражающие объективные закономерности) и эмпирические, опытные, которые отражают опыт отдельного человека или коллективов людей.

В зависимости от того, что характеризуют знания, они разделяются на фактуальные (декларативные, предметные знания) и процедурные (операционные). Первые – это описания фактов и явлений, а также взаимосвязей между ними. Вторые есть описания способов действий, которые возможно при манипулировании фактами для достижения поставленных целей. Если фактуальные знания отвечают на вопрос «Что (делать)?», то процедурные – на вопрос «Как (как делать)?»

В ИИС различают также знания коллективные и знания индивидуальные. Индивидуальные знания имеют особое значение в экспертных системах, в системах принятия решений, имитирующих рассуждения эксперта в ходе решения задач и рассуждения ЛПР в ходе анализа и выбора альтернатив.

При представлении знаний в ИИС выделяют также термин метазнания – это знания о знаниях, о том, как взаимосвязаны отдельные сегменты знаний между собой, о порядке их использования в процессе вывода решений.

Появление систем, основанных на знаниях (СОЗ), стало важным событием в развитии искусственного интеллекта. Основанные на экспертных знаниях системы (экспертные системы), явились первым примером того, что ИИ – это не только исследования или компьютерные игры, но это и реальный бизнес, это системы, которые могут приносить их пользователям дополнительные доходы, исчисляемые миллионами.

<p align="right"><a href="#readme-top">К содержанию ^</a></p>

##

<h2 id="7"> 7. Модели представления знаний </h2>

Распространены четыре основных МПЗ:

- Продукционная МПЗ
- Семантическая сеть МПЗ
- Фреймовая МПЗ
- Формально логическая МПЗ

<h3>1. Продукционная МПЗ</h3>

В основе продукционной модели представления знаний находится конструктивная часть, продукция(правило):

> IF <условие>, THEN <действие>

Продукция состоит из двух частей: условие — антецендент, действие — консеквент. Условия можно сочетать с помощью логических функций AND, OR.

Антецеденты и консеквенты составленных правил формируются из атрибутов и значений.

Пример:

> IF температура реактора подымается THEN добавить стержни в реактор

В базе данных продукционной системы хранятся правила, истинность которых установлена к за ранее при решении определенной задачи. Правило срабатывает, если при сопоставлении фактов, содержащихся в базе данных с антецедентом правила, которое подвергается проверке, имеет место совпадение. Результат работы правила заносится в базу данных.

<h3>2. Семантическая сеть МПЗ</h3>

В основе продукционной модели лежит ориентированный граф.  
Вершины графа — понятия, дуги — отношения между понятиями.

Особенностью является наличие трех типов отношений:

- класс — подкласс
- свойство — значение
- пример элемента класса

По количеству типов отношений выделяют однородные и неоднородные семантические сети. Однородные имею один тип отношения между всеми понятиями, следовательно, не однородные имею множество типов отношений.

Все типы отношений:

- часть — целое
- класс — подкласс
- элемент — количество
- атрибутивный
- логический
- лингвистический

<h3>3. Фреймовая МПЗ</h3>

Предложил Марвин Мински в 1970 году. В основе фреймовой модели МПЗ лежит фрейм. <b>Фрейм</b> — это образ, рамка, шаблон, которая описывает объект предметной области, с помощью слотов. <b>Слот</b> — это атрибут объекта. Слот имеет имя, значение, тип хранимых данных, демон. <b>Демон</b> — процедура автоматически выполняющаяся при определенных условиях. Имя фрейма должно быть уникальным в пределах одной фреймовой модели. Имя слота должно быть уникальным в пределах одного фрейма.

Слот может хранить другой фрейм, тогда фреймовая модель вырождается в сеть фреймов.

<h3>4. Формально логическая МПЗ</h3>

В основе формально логической МПЗ лежит предикат первого порядка. Подразумевается, что существует конечное, не пустое множество объектов предметной области. На этом множестве с помощью функций интерпретаторов установлены связи между объектами. В свою очередь на основе этих связей строятся все закономерности и правила предметной области. Важное замечание: если представление предметной области не правильное, то есть связи между объектами настроены не верно или не в полной мере, то правильная работоспособность системы будет под угрозой.

Пример:

> A1 = <идет дождь> A2 = <небо в тучах> A3 = <солнечно>
> \
> IF A1 AND A2 THEN <взять зонтик>

<i>Важно</i>: Стоит заметить, что формально логическая МПЗ схожа с продукционной. Частично это так, но они имеют огромную разницу. Разница состоит в том, что в продукционной МПЗ не определены никакие связи между хранимыми объектами предметной области.

<p align="right"><a href="#readme-top">К содержанию ^</a></p>

##

<h2 id="8"> 8. Продукционная модель (правила продукций)</h2>

<b>Продукционная модель знания</b> — модель, основанная на правилах, позволяет представить знание в виде предложений типа «Если (условие), то (действие)»

Продукционная модель обладает тем недостатком, что при накоплении достаточно большого числа (порядка нескольких сотен) продукций они начинают вследствие необратимости дизъюнкций противоречить друг другу. В этом случае разработчики начинают усложнять систему, включая в неё модули нечёткого вывода или иные средства разрешения конфликтов, — правила по приоритету, правила по глубине, эвристические механизмы исключений, возврата и т. п.

Продукционная модель часто дополняется определённым порядком, вводимым на множестве продукций, что упрощает механизм логического вывода. Порядок может выражаться в том, что отдельная следующая по порядку продукция может применяться только после попыток применения предшествующих ей продукций. Примерно похожее влияние на продукционную модель может оказать использование приоритетов продукций, означающее, что в первую очередь должна применяться продукция, имеющая наивысший приоритет.

Рост противоречивости продукционной модели может быть ограничен путём введения механизмов исключений и возвратов. Механизм исключений означает, что вводятся специальные правила-исключения. Их отличает большая конкретность в сравнении с обобщёнными правилами. При наличии исключения основное правило не применяется. Механизм возвратов же означает, что логический вывод может продолжаться в том случае, если на каком-то этапе вывод привёл к противоречию. Просто необходимо отказаться от одного из принятых ранее утверждений и осуществить возврат к предыдущему состоянию.

Противоречия в базах знаний на языке Пролог выявляются автоматически за счет использования автоматического доказательства теорем со встроенным в систему Пролог механизмами перебора с возвратами, организующего поиск информации в базах знаний и выводом найденной информации в качестве результатов информационного поиска.

<p align="right"><a href="#readme-top">К содержанию ^</a></p>

##

<h2 id="9"> 9. Представление и обработка непределенности в продукционных системах</h2>

http://www.systematy.ru/articles/_33_predstavlenie_i_obrabotka_neopredelennosti_v_produktsionnyih_sistemah

<p align="right"><a href="#readme-top">К содержанию ^</a></p>
<p align="right"><a href="#readme-top">К содержанию ^</a></p>

##

<h2 id="10"> 10. Байесова модель</h2>

https://habr.com/ru/post/170545/

<p align="right"><a href="#readme-top">К содержанию ^</a></p>

##

<h2 id="11"> 11. Сетевые модели и графы</h2>

<b>Сетевая модель</b> — графическое изображение плана выпол­нения комплекса работ, состоящего из нитей (работ) и узлов (событий), которые отражают логическую взаимосвязь всех операций. В основе сетевого моделирования лежит изображе­ние планируемого комплекса работ в виде графа.

<b>Граф</b> — схе­ма, состоящая из заданных точек (вершин), соединенных сис­темой линий. Отрезки, соединяющие вершины, называются ребрами (дугами) графа. Ориентированным называется такой граф, на котором стрелкой указаны направления всех его ребер (дуг), что позволяет определить, какая из двух его граничных вершин является начальной, а какая — конечной. Исследование таких сетей проводится методами теории графов.

Теория графов оперирует понятием пути, объединяющим последовательность взаимосвязанных ребер. Контур означает такой путь, у которого начальная вершина совпадает с конеч­ной.

<b>Сетевой график</b> — это ориентированный граф без конту­ров. В сетевом моделировании имеются два основных элемен­та — работа и событие.

За более подробной информацией сюда:

https://matica.org.ua/metodichki-i-knigi-po-matematike/osnovy-matematiki-i-ee-prilozheniia-v-ekonomicheskom-obrazovanii-krass-m-s-chuprynov-b-p/30-1-setevye-modeli-osnovnye-poniatiia-setevoi-modeli

<p align="right"><a href="#readme-top">К содержанию ^</a></p>

##

<h2 id="12"> 12. Рейтинговая модель</h2>

Идея этой модели представления знаний и вывода решений базируется так же на идее диалога с пользователем, когда пользователю задаются вопросы и, возможно, предлагаются варианты ответов.
Таки образом, как и в дереве решений знаниями эксперта будут эти самые вопросы и варианты ответов. Однако, на этом сходство заканчивается.

Пусть имеются гипотезы G1, G2, G3, а работа системы состоит в сборе свидетельств в пользу этих гипотез. Будем говорить, что в ходе вывода строится рейтинг каждой из названных гипотез. 
Гипотеза, рейтинг которой в конце вывода будет наибольшим, принимается верной. Такой гипотезой может быть класс пользователя или типовое состояние в некоторой систем.

Каждый вариант ответа вносит свой балл в рейтинг каждой из гипотез , причем как положительный, так и отрицательный. Тогда по мере получения от пользователя ответов на вопросы x1,x2,x3,…, xi, в системе формируется рейтинг каждой из гипотез. При этом могут быть предусмотрены также и варианты ответов вида «неизвестно» или «не знаю». Множество гипотез, вопросов, вариантов ответов и баллов за/против гипотезы у каждого варианта ответа составляет основу базы экспертных знаний.

Для создания разных моделей вывода остается включить в базу знаний правила выбора вопросов и окончания вывода. Могут быть предусмотрены такие варианты:

- выбор в заданном порядке или случайным образом всех вопросов из БЗ и подведение итогов по окончанию «тестирования». Этот вариант близок к диалогу на основе дерева решений, однако, может быть даже хуже дерева решений, т.к. возможно, будет содержать в себе гораздо больше вопросов пользователю ;
- выбор вопросов, ответы которых дают наибольший вклад в рейтинг той или иной гипотезы. Вывод заканчивается, когда рейтинг одной из гипотез по сравнению с рейтингами других будет преобладающим. Этот вариант хорош тем, что можно существенно ограничить число вопросов, а сам диалог сделать адаптивным. зависящим от ответов пользователя.

Основная сложность данной модели состоит в подборе множеств вопросов, ответов и коэффициентов рейтингов. Недостатком , по видимому, будет и то, что не в каждой области и не каждый эксперт сможет, свою логику решения профессиональных задач воспроизвести в терминах этой модели. В то же время, эта модель позволяет относительно легко перейти от субъективных знаний одного эксперта к базе знаний с комбинированными экспертными оценками.

<p align="right"><a href="#readme-top">К содержанию ^</a></p>

##

<h2 id="13"> 13. Нечеткая модель</h2>

В условиях, когда описание подлежащей решению проблемы заведомо является неточным или неполным, традиционные методы построения моделей не приводят к удовлетворительным результатам. В таких случаях целесообразно воспользоваться подходами, которые специально ориентированы на построение моделей, учитывающих неполноту и неточность исходных данных. Именно в таких ситуациях наиболее конструктивной оказывается технология нечеткого моделирования, основанная на нечеткой логике. Подтверждение этому — впечатляющие решения многих практических задач, полученные за последние десятилетия на основе нечеткого моделирования.

Например, нечеткие контроллеры на четырех нефтеперерабатывающих заводах крупной японской нефтяной компании Idemitsu Kosan Со., Ltd. обеспечивают ежегодный экономический эффект более 200 млн японских иен.

Нечеткая логика предназначена для формализации способности человека к неточным или приближенным рассуждениям, позволяющим описывать ситуации с неопределенностью. Использование нечетких моделей дало возможность строить базы знаний и экспертные системы нового поколения, способные хранить и обрабатывать неточную информацию.

Такие системы разработаны и успешно внедрены в таких областях, как финансовый менеджмент, финансовый анализ, биржевое прогнозирование, исследование рисковых и критических операций, управление транспортом, управление технологическими процессами, управление бытовой техникой, медицинская и техническая диагностика, распознавание образов, прогнозирование землетрясений и др.

В общем случае под <i>нечеткой моделью</i> понимается информационно-логическая модель системы, построенная на основе теории нечетких множеств и нечеткой логики. Подход к анализу систем на основе теории нечетких множеств является альтернативой общепринятым количественным методам. В основе нечеткой логики лежит теория нечетких множеств. Понятие нечеткого множества формализует нечеткую информацию для построения математических моделей.

В основе этого понятия лежит представление о том, что составляющие данное множество элементы, обладающие некоторым общим свойством, могут обладать этим свойством в различной степени и, следовательно, принадлежать к данному множеству с различной степенью. При таком подходе высказывания типа «элемент принадлежит данному множеству» нуждаются в дополнении, поскольку требуется указать, в какой степени рассматриваемый элемент удовлетворяет свойствам данного множества. Это дает возможность определять понятия, нечеткие по самой своей природе: «хороший», «популярный», «слабый», «выгодный» и т.д.

Нечеткое множество представляет собой совокупность элементов произвольной природы, относительно которых нельзя с полной определенностью утверждать — принадлежит ли тот или иной элемент рассматриваемой совокупности данному множеству или нет.

Формальное определение нечеткого множества имеет следующий вид.
<b>Определение: </b>Нечетким множеством А называется совокупность упорядоченных нар (кортежей), составленных из элементов х базового (универсального) множества X и соответствующих значений рл(х):

Нечеткие множества могут быть заданы одним из двух основных способов:

1. явным перечислением элементов и соответствующих им значений функции принадлежности;
2. указанием вида функции принадлежности — аналитически или графически.

<p align="right"><a href="#readme-top">К содержанию ^</a></p>

##

<h2 id="14"> 14. Фреймы и объективно-ориентирована представление знаний</h2>

Концепция фреймов была разработана и предложена для представления знаний в 70-х годах 20 века американским ученым, профессором Массачусетского технологического института Марвиным Минским, который считается одним из наиболее авторитетных ученых в области ИИ.Минский определил фрейм как структуру данных для представления стереотипных ситуаций или типовых объектов. Особенностью этого подхода стало объединение в одной структуре как декларативных знаний об объектах, их свойствах и состояниях, так и процедурные знания о поведении объектов, о методах извлечения информации и достижения целей. Заранее отметим сходство этой концепции и понятия <b>«фрейм»</b>с современным понятиями <b>«объект»</b>, <b>«класс»</b> в объектно-ориентированном программировании.

Идея фреймов состояла в том, чтобы сконцентрировать все знания о некотором классе объектов или событий в единой структуре данных, а не распределять их между множеством более мелких структур вроде логических формул или правил продукций. Такие знания либо сосредоточены в самой структуре данных, либо доступны из этой структуры (например, хранятся в другой структуре, связанной с фреймом)

Например, фрейм «птица» содержит в себе знания о птицах вообще, их признаках, свойствах, наличии оперения, крыльев и умении летать. В системе фреймов отражаются отношения между фреймами. В первую очередь - отношение тип-подтип (вид-род), которое позволяет ввести описание, например, конкретного вида птицы «дятел». В этом случае фрейм «Дятел» наследует некоторые данные и процедуры из фрейма «Птица», но будет содержать в себе и новые сведения (например, способность долбить клювом по дереву).

Фрейм представляет собой совокупность ячеек с данными – слотов, а также процедур, запускаемых при выполнении определенных условий. Заполнителями слотов (т.е. его значениями) могут быть конкретные данные, ссылки на массивы, диапазоны значений, множества, ссылки на другие фреймы и даже продукционные правила для логического вывода значений.

Предусматриваются процедуры, присоединенные к слотам, которые могут запускать операции по добавлению, вычислению или передаче значений слотов при обращении к слотам. Такие процедуры называются демонами (процедуры-демоны). Другие, служебные процедуры (процедуры-слуги) могут определять поведение всего объекта в некотором состоянии или при некоторых внешних условиях и запускаются по запросу.

Можно сказать, что сама технология объектно-ориентированного подхода стала результатом практического внедрения концепции фреймов в инженерию программирования (не только применительно к созданию интеллектуальных систем). Важным подспорьем в этом стало создание специальных языков для представления знаний с помощью фреймов, к числу первых среди которых относятся язык <b>KRL</b> (Knowledge Representation Language), объектно-ориентированные расширения языка для ИИ <b>LISP</b> – <b>LOOPS</b>, <b>FLAVORS</b>, <b>COOL</b>
и др.

<p align="right"><a href="#readme-top">К содержанию ^</a></p>

##

<h2 id="15"> 15. Ситуационный подход в представлении знаний и выводе решений</h2>

В большинстве эвристических моделей знаний реализуется вывод на основании дедуктивных рассуждений, когда от общих закономерностей, зафиксированных в базе знаний, система пере-ходит к выводу решения в конкретной, частной обстановке.

Еще один способ вывода – по аналогии – реализуется в си-туационной модели представления знаний и вывода решений.

Алгоритм ситуационного вывода включает следующие этапы:

- идентификация текущей ситуации ;
- поиск в базе знаний аналога - ситуации, наиболее сходной по некоторому критерию с текущей;
- выбор из БЗ решения, соответствующего найденной ситуации.

На каждом из этих этапов при построении автоматизирован-ной ситуационной системы возникают свои трудности. Так, при идентификации необходимо выбрать способ структурированного описания ситуаций, который позволит далее выполнить этап рас-познавания. Кроме того, сам процесс формирования описания Sitтек предполагает опрос пользователя и/или некоторых иных информационных источников, баз данных, датчиков и др.

Определить, какие вопросы и в какой последовательности должны быть заданы - это еще одна трудность, которая возникает на эта-пе идентификации. На этапе распознавания трудность составля-ет выбор или построение способов и критериев для оценки сход-ства ситуаций. На этапе вывода решений – способы представле-ния решений пользователю; кроме того, отдельной задачей явля-ется сама конструкция решения.Один из подходов, позволяющий преодолеть названные труд-ности и реализовать вывод решения с помощью механизма дере-ва ситуаций.

Концептуальной основой ситуационного подхода является принятие решений «по аналогии», когда в базе знаний интеллектуальной системы хранятся описания типовых ситуаций и тех решений (управлений), которые целесообразно применить в подобных ситуациях. Сравнивая текущую ситуацию с имеющимися в базе знаний, можно распознать класс текущей ситуации, т.е. выбрать ту типовую ситуацию из БЗ, которая наиболее близка текущей.

Разработаны различные способы представления, распознавания ситуаций и вывода решений (в большинстве случаев - на основе аппарата теории нечетких множеств)

Рассмотрим некоторые теоретические аспекты ситуационной модели представления знаний и вывода решений. Если в продукционных системах вывод решений выполняется на основе на дедукции (от известных общих фактов и правил, фиксированных БЗ, к выводу решения в частном случае при имеющихся данных, в складывающейся обстановке) , то в ситуационных системах реализован вывод по аналогии – поиск решения для текущей ситуации выполняется путем нахождения аналогичной ситуации в прошлом. Таким образом, ситцуационная база знаний (СБЗ) должна содержать в себе описания аналогов - ситуаций и тех решений, которые являются рациональными в этих ситуациях.

В отличие от моделей знаний на основе правил продукций «Если … То…» ситуационная модель описывает не отдельные факты и взаимосвязи между ними, а цельные образы сложившихся в системе условий, что упрощенно можно представить правилом «Если <ситуация> То …».

Ситуационная база знаний может быть представлена множеством пар <ситуация - Sit, решение - R>:

> <b>СБЗ = {< Sitk, Rk> | k =1, 2, 3, ...}</b>  
> <i>или</i>  
> <b>СБЗ = {{Sitk}, {Rk}> | k =1, 2, 3, ...}</b>

Процедурная составляющая этой модели – базовый алгоритм ситуационной модели - включает этапы

- идентификация текущей ситуации с формированием формализованного описания ситуации Sitтек (этап идентификации)
- поиск в базе знаний ситуации Sit\*, наиболее сходной по некоторому критерию с текущей (этап анализа и отбора). В случае, когда Sitk представляют собой описание типовой ситуации k-го класса, этот этап называется этапом распознавания класса текущей ситуации;
- выбор решения R*Û Sit* и выдача пользователю рекомендуемого решения R\* или некоторого подмножества выбранных решений (этап вывода решения).

<b>Трудности</b>

- при идентификации необходимо выбрать способ структурированного описания ситуаций, который позволит далее выполнить этап распознавания
- сам процесс формирования описания Sitтек предполагает опрос пользователя и/или некоторых иных информационных источников, баз данных, датчиков и др
- Определить, какие вопросы и в какой последовательности должны быть заданы - это еще одна трудность, которая возникает на этапе идентификации
- На этапе распознавания трудность составляет выбор или построение способов и критериев для оценки сходства ситуаций
- На этапе вывода решений – способы представления решений пользователю

Среди формальных ситуаций можно выделить три основных типа: обобщенная, конкретная и конкретизированная ситуации.
Обобщенная ситуация в общем виде задается набором атрибутов (признаков ситуации) и их типов значений или диапазонов значений:

<p align="right"><a href="#readme-top">К содержанию ^</a></p>

##

<h2 id="16"> 16. Системы интеллектуального анализа данных. Извлечение знаний из данных</h2>

Системы ИАД реализуют принципиально иную стратегию получения знаний, нежели СОЗ. Здесь не система получает знания от человека – эксперта, а, напротив, человек получает от системы знания
<b>Data Mining</b>
Например, такого рода:

- причинно-следственные и хронологические связи между событиями. Так, исследования в супермаркете могут показать, что 65% купивших пиво, покупают и чипсы. А вот при наличии скидки за такой комплект оказывается, что чипсы приобретают уже 90% покупателей;
- взаимосвязи между данными и правилами классификации объектов. Например, на основе анализа данных о покупателях можно выявить правила их классификации с тем, чтобы отнести каждого покупателя (в том числе нового) к тому или иному классу и подобрать для него индивидуальный пакет услуг;
- логические взаимосвязи между данными, на основе которых по некоторым значениям параметров А, В, С можно предположить (предсказать) значение параметра D;
- кластеризации – устойчивые группы в множестве объектов, описываемых некоторым набором данных. В отличие от классификации сами группы - кластеры здесь неизвестны, их требуется определить. Так, при анализе некоторого множества данных о покупателях можно выявить группы и признаки покупателей, предпочитающих определенный вид товара и способ обслуживания;

Чем же привлекательны методы Data Mining для современных менеджеров и чем они отличны от методов статистики?

- предполагают наличие больших объемов однородных данных, т.е. тех, где можно выявить тенденции (такие данные и в нужном объеме есть далеко не всегда);
- ориентированы на использование средних величин (известный по этому поводу казус – по отчетам средняя температура больных в больнице 36,6, т.е все в порядке! Правда, у некоторых пациентов температура за 40, а у других – 28…);
- выражают результаты своей работы в виде абстрактных формул, которые не всегда понятны менеджерам и не вызывают у них должного доверия для принятия решений;
- применимы более для проверки гипотез, чем для их выявления.

Характер работы с данными у методов data mining ближе к «человеческому», т.е. они могут выводить свои суждения при относительно небольших объемах данных, пусть и с разной степенью уверенности.

В заключение отметим некоторые прикладные задачи, которые решаются с помощью упомянутых в этой главе систем и которые служат примером того, насколько современные ИИС ориентированы на реальный бизнес:

- мониторинг и классификации телефонных вызовов в масштабе реального времени;
- прогноз потребления электроэнергии;
- мониторинг качества данных продаж сети розничной торговли;
- выявление мошенничества в сфере здравоохранения и страхования;
- анализ клиентской базы и др.

<p align="right"><a href="#readme-top">К содержанию ^</a></p>

##

<h2 id="17"> 17. Архитектура многослойных нейронных сетей</h2>

<b>Многослойная нейронная сеть</b> (англ. Multilayer neural network) — нейронная сеть, состоящая из входного, выходного и расположенного(ых) между ними одного (нескольких) скрытых слоев нейронов.

Помимо входного и выходного слоев эти нейронные сети содержат промежуточные, скрытые слои. Такие сети обладают гораздо большими возможностями, чем однослойные нейронные сети, однако методы обучения нейронов скрытого слоя были разработаны относительно недавно.

Работу скрытых слоев нейронов можно сравнить с работой большого завода. Продукт (выходной сигнал) на заводе собирается по стадиям на станках. После каждого станка получается какой-то промежуточный результат. Скрытые слои тоже преобразуют входные сигналы в некоторые промежуточные результаты.

Рассмотрим основные элементы в структуре НС. Отметим, что хотя термины, используемые в НС, пришли сюда из биологии, современные исследователи и разработчики нейрокомпьютеров не претендуют на близкое сходство своих моделей и структур с реальным человеческим мозгом. Главным является наделением нейросети возможностями решать конкретные задачи, а не имитировать с максимальной точностью биологический процесс.На рисунке показан искусственный нейрон (далее слово «искусственный» не употребляется), точнее модель нейрона – элементарный процессор НС.
<img src="./assets/17.png">

Нейрон получает на входе сигналы x1, x2, x3,…, xN. И суммирует их с весовыми коэффициентами w:

<p align="right"><a href="#readme-top">К содержанию ^</a></p>

##

<h2 id="18"> 18. Активация нейронной сети посредством прямого распространения</h2>

<b>Функции активации</b>
Используется как орган принятия решений на выходе нейрона. Нейрон изучает линейные или нелинейные границы принятия решений на основе функции активации. Он также оказывает нормализующее влияние на выход нейронов, что предотвращает выход нейронов после нескольких слоев, чтобы стать очень большим, за счет каскадного эффекта. Есть три наиболее часто используемых функции активации.

<b>Сигмоида</b>
Он отображает входные данные (ось x) на значения от 0 до 1.
<img src="./assets/sigmoid.png">

<b>Tanh</b>
Похожа на сигмовидную функцию, но отображает входные данные в значения от -1 до 1.
<img src="./assets/tanh.png">

<b>Rectified Linear Unit (ReLU)</b>
Он позволяет проходить через него только положительным значениям. Отрицательные значения отображаются на ноль.
<img src="./assets/relu.png">

<b>Функция активации</b>
может быть другой, например, функция Unit Step, leaky ReLU, Noisy ReLU, Exponential LU и т.д., которые имеют свои плюсы и минусы.

<b>Входной слой</b>
Это первый слой нейронной сети. Он используется для передачи и приёма входных данных или функций в сеть.

<b>Выходной слой</b>
Это слой, который выдает прогнозы. Функция активации, используемая на этом уровне, различается для разных задач. Для задачи двоичной классификации мы хотим, чтобы на выходе было либо 0, либо 1. Таким образом, используется сигмовидная функция активации. Для задачи мультиклассовой классификации используется Softmaxએ (воспринимайте это как обобщение сигмоида на несколько классов). Для задачи регрессии, когда результат не является предопределенной категорией, мы можем просто использовать линейную единицу.

<b>Скрытый слой</b> (Скрытые слои тоже преобразуют входные сигналы в некоторые промежуточные результаты.)
Сеть прямого распространения применяет к входу ряд функций. Имея несколько скрытых слоев, мы можем вычислять сложные функции, каскадируя более простые функции. Предположим, мы хотим вычислить седьмую степень числа, но хотим, чтобы вещи были простыми (поскольку их легко понять и реализовать). Вы можете использовать более простые степени, такие как квадрат и куб, для вычисления функций более высокого порядка. Точно так же вы можете вычислять очень сложные функции с помощью этого каскадного эффекта. Наиболее широко используемый скрытый блок — это тот, где функция активацииએ использует выпрямленный линейный блок (ReLU). Выбор скрытых слоёв — очень активная область исследований в машинном обучении. Тип скрытого слоя отличает разные типы нейронных сетей, такие как CNNએ, RNNએ и т.д. Количество скрытых слоев называется глубиной нейронной сети. Вы можете задать вопрос: сколько слоев в сети делают ее глубокой? На это нет правильного ответа. В общем случае, более глубокие сети могут научиться более сложным функциям.

<b>Как сеть учится?</b>
Обучающие образцы передаются по сети, и выходные данные, полученные от сети, сравниваются с фактическими выходными данными. Эта ошибка используется для изменения веса нейронов таким образом, чтобы ошибка постепенно уменьшалась. Это делается с помощью алгоритма обратного распространения ошибки, также называемого обратным распространением. Итеративная передача пакетов данных по сети и обновление весов для уменьшения ошибки называется стохастический градиентный спускએ (SGD). Величина, на которую изменяются веса, определяется параметром, называемым «Скорость обучения». Подробности SGD и backprop будут описаны в отдельном посте.

Используя один нейрон, мы можем узнать только линейную границу решения.
Нам пришлось придумать преобразования функций (например, квадрат функций или продукт функций) путем визуализации данных. Этот шаг может быть сложным для данных, которые нелегко визуализировать.

<p align="right"><a href="#readme-top">К содержанию ^</a></p>

##

<h2 id="19"> 19. Распараллеливание процесса обучения нейронных сетей с помощью TensorFlow </h2>

<b>Синхронное обучение</b>
При синхронном обучении каждому воркеру/ускорителю отправляют разные фрагменты данных. У каждого устройства имеется полная копия модели, которая обучается лишь на части данных. Прямой проход во всех этих моделях начинается в одно и то же время. Все они вычисляют различные выходные данные и градиенты.
В этот момент все устройства обмениваются друг с другом информацией, осуществляется агрегирование градиентов с использованием вышеописанного алгоритма all-reduce. После того, как все градиенты окажутся скомбинированными, их отправляют обратно на устройства. Теперь все устройства выполняют обратный проход и, в обычном режиме, обновляют локальную копию весов. Следующий прямой проход не начнётся до тех пор, пока все переменные не будут обновлены. Именно поэтому такая схема обучения и называется «синхронной». В каждый момент времени в распоряжении всех устройств имеются в точности одни и те же веса, несмотря на то, что модели, работающие на них, выдают разные градиенты, так как обучаются они на разных данных. Но обновление весов производится с учётом всех данных.

<b>Стратегия MirroredStrategy</b>
В документации по TensorFlow говорится следующее: «Каждая переменная в модели дублируется (зеркалируется) в каждой из копий. Все вместе эти переменные формируют единственную абстрактную переменную, называемую MirroredVariable. Синхронизация этих переменных друг с другом поддерживается благодаря применению к ним одинаковых изменений, обновляющих их значения». Полагаю, эта выдержка из документации объясняет причину того, что в названии обсуждаемой тут стратегии есть слово «зеркалирование».

<b>Стратегия MirroredStrategy</b>
По аналогии с MirroredStrategy, позволяет организовать обучение моделей с использованием нескольких воркеров. При её использовании, как и прежде, создаются копии всех переменных на всех воркерах, а обучение выполняется синхронно.

<!-- <img src="./assets/back-propagation.png"> -->

<b>Стратегия MultiWorkerMirroredStrategy</b>
По аналогии с MirroredStrategy, позволяет организовать обучение моделей с использованием нескольких воркеров. При её использовании, как и прежде, создаются копии всех переменных на всех воркерах, а обучение выполняется синхронно.

<b>Стратегия CentralStorageStrategy</b>
Ещё одна стратегия, о которой стоит упомянуть — это «central storage strategy» (стратегия, использующая центральное хранилище). Она применима лишь в окружениях, где имеется единственный компьютер с несколькими GPU. Если имеющиеся в нашем распоряжении GPU не могут хранить всю модель, мы назначаем CPU центральным «хранителем» информации, ответственным за поддержание глобального состояния модели. В этой связи переменные не зеркалируются на различных устройствах, вместо этого все они находятся в ведении CPU.
В результате CPU отправляет переменные видеоускорителям, которые выполняют обучение модели, вычисляют градиенты, обновляют веса и отправляют их обратно центральному процессору, который комбинирует их с использованием операции reduce.

<b>Стратегия ParameterServerStrategy</b>
Самой распространённой стратегией асинхронного обучения является «parameter server strategy» (стратегия, использующая сервер параметров). Когда имеется кластер воркеров, им можно назначать разные роли. Другими словами, некоторые устройства делают серверами параметров, а остальные — воркерами, занимающимися обучением модели.
Серверы параметров хранят параметры (глобальное состояние) модели и ответственны за их обновление.
Воркеры, занимающиеся обучением модели, выполняют код цикла обучения и выдают результаты вычисления градиентов и функций потерь на основе обрабатываемых ими данных.

1. Мы, как и прежде, создаём копии модели на всех воркерах.
2. Каждый «обучающий» воркер загружает параметры с сервера параметров.
3. Эти воркеры выполняют цикл обучения.
4. После завершения работы они отправляют градиенты серверу параметров, который обновляет веса модели

Вы, глядя на это, возможно, уже сделали вывод о том, что такой подход позволяет проводить обучение модели в пределах одного воркера независимо от других воркеров, и о том, что его применение позволяет масштабировать обучение

<b>Асинхронное обучение</b>
У синхронного обучения есть множество сильных сторон, но системы, основанные на таком обучении, может быть достаточно трудно масштабировать. Более того, масштабирование таких систем может привести к тому, что некоторые воркеры длительное время будут пребывать в состоянии простоя. Если воркеры различаются в плане функциональных возможностей, если некоторые из них отключаются для выполнения их обслуживания, или если им назначены различные приоритеты — это означает, что асинхронный подход может оказаться более удачным выбором, так как воркерам не придётся друг друга ждать.
Принимая решение о том, какой подход к обучению выбрать — синхронный или асинхронный, можно пользоваться следующими рекомендациями, основанными на практике, которые, конечно, не являются универсальными:

- Если имеется множество маленьких, ненадёжных устройств с ограниченными возможностями — лучше прибегнуть к асинхронному подходу.
- Если в нашем распоряжении есть мощные устройства, связанные быстрой сетью, то, возможно, лучше будет применить синхронный подход к обучению.
  Теперь предлагаю выразить суть асинхронного подхода к обучению простыми словами.
  Отличие асинхронного обучения от синхронного заключается в том, что воркеры выполняют обучение модели с разной скоростью, при этом каждому из них не нужно ждать остальных. Как реализовать это на практике?

<p align="right"><a href="#readme-top">К содержанию ^</a></p>

##

<h2 id="20"> 20. Классификация изображений с помощью глубоких сверточных нейронных сетей</h2>

<p align="right"><a href="#readme-top">К содержанию ^</a></p>

##

<h2 id="21"> 21. Строительные блоки сверточных нейронных сетей</h2>

<p align="right"><a href="#readme-top">К содержанию ^</a></p>

##

<h2 id="22"> 22. Понятие сверточных нейронных сетей</h2>

<b>Свёрточная нейронная сеть</b> — специальная архитектура искусственных нейронных сетей, предложенная Яном Лекуном в 1988 году и нацеленная на эффективное распознавание образов, Таким образом, идея свёрточных нейронных сетей заключается в чередовании свёрточных слоёв и субдискретизирующих.
Структура сети — однонаправленная (без обратных связей), принципиально многослойная. Для обучения используются стандартные методы, чаще всего метод обратного распространения ошибки. Функция активации нейронов (передаточная функция) — любая, по выбору исследователя.
Название архитектура сети получила из-за наличия операции свёртки, суть которой в том, что каждый фрагмент изображения умножается на матрицу (ядро) свёртки поэлементно, а результат суммируется и записывается в аналогичную позицию выходного изображения.
Работа свёрточной нейронной сети обычно интерпретируется как переход от конкретных особенностей изображения к более абстрактным деталям, и далее к ещё более абстрактным деталям вплоть до выделения понятий высокого уровня. При этом сеть самонастраивается и вырабатывает сама необходимую иерархию абстрактных признаков (последовательности карт признаков), фильтруя маловажные детали и выделяя существенное.

<p align="right"><a href="#readme-top">К содержанию ^</a></p>

##

<h2 id="23"> 23. Выполнение дискретных сверток в сверточной нейронной сети</h2>

<p align="right"><a href="#readme-top">К содержанию ^</a></p>

##

<h2 id="24"> 24. Работа с множественными входными или цветовыми каналами в сверточной нейронной сети</h2>

<p align="right"><a href="#readme-top">К содержанию ^</a></p>

##

<h2 id="25"> 25. Архитектура многослойной сверточной нейронной сети</h2>

<p align="right"><a href="#readme-top">К содержанию ^</a></p>

<style>
.back-propagation {
  display: flex;
  flex-direction: column;
  align-items: center;
  justify-content: center;
}
